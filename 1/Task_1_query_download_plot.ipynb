{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Importing necessary libaries and applying settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime # used for time format conversion\n",
    "import os # access to host system to create directories and write files\n",
    "import ftplib # libary to access ftp server\n",
    "import urllib3 \n",
    "import codecs\n",
    "from zipfile import ZipFile # used for unzipping zip files\n",
    "import numpy as np # numpy arrays and functions for example replacing bad values with true NotaNumber\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# making plots available in jupyter output line\n",
    "import pandas as pd # for pandas dataframe to read csv\n",
    "#pd.options.display.max_seq_items = None # pandas printing options\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "# pd.set_option('display.width', 1000)"
   ]
  },
  {
   "source": [
    "## Defining variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_server = \"opendata.dwd.de\" # root of file server\n",
    "ftp_user = \"anonymous\"\n",
    "ftp_passwd = \"\"\n",
    "ftp_dir =  \"/climate_environment/CDC/observations_germany/climate/annual/kl/historical/\" # directory\n",
    "state = \"Bayern\" # Selected state to filter\n",
    "years = [2017, 2018, 2019] # selected years\n",
    "nyears = len(years) # length of years list\n",
    "year_from = datetime.strptime(str(years[0])+\"0101\", '%Y%m%d') # lowest year from the list\n",
    "year_to = datetime.strptime(str(years[nyears-1])+\"1231\", '%Y%m%d') # highest year from the list\n",
    "stations_fname = \"\" # initializing variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_ftp(): # establishing connection to ftp server and check if it was successfull\n",
    "    ftp = ftplib.FTP(ftp_server) # creating ftp server instance\n",
    "    res = ftp.login(user = ftp_user, passwd = ftp_passwd) # logging in to server\n",
    "    ret = ftp.cwd(ftp_dir) # Changing into correct ftp directory\n",
    "    return ftp # return configured and connected ftp instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_ftp_dir():\n",
    "    lines = [] # buffer for storing lines of ftp directory\n",
    "    flist = [] # buffer for temporarily storing station_idm, zip file names and product file name\n",
    "    try:\n",
    "        res = ftp.retrlines(\"NLST\", lines.append) # retrieve lines with NLST ftp command, which lsits file names including extention, the returned lines are appended to the lines buffer\n",
    "    except:\n",
    "        return\n",
    "    global stations_fname # setting global variable to use filename later\n",
    "    stations_fname = lines[0] # storing first line, which is the file name of the station description\n",
    "    lines.pop(0) # removing station description file from buffer to read only zip files later\n",
    "    for line in lines: # looping through elements of the lines buffer\n",
    "        pname = \"produkt_klima_jahr_\"+line.split(\"_\")[3]+\"_\"+line.split(\"_\")[4]+\"_\"+line.split(\"_\")[2]+\".txt\" # generating product file name\n",
    "        flist.append([int(line.split(\"_\")[2]), line, pname]) # reading variables into temporary list\n",
    "    df_ftp_dir = pd.DataFrame(flist,columns=[\"station_id\", \"fname\", \"pname\"]) # creating a pandas dataframe from flist, defining column names for elements in the list\n",
    "    df_ftp_dir.set_index(\"station_id\", inplace = True) # setting station_id column as index and replacing the standard numeration\n",
    "    return df_ftp_dir # return the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_station_desc_query():\n",
    "    try:\n",
    "        ftp.retrbinary('RETR '+ stations_fname, open(stations_fname, 'wb').write) # retrieve the binary code from the stations_fname file from ftp and writing to a newly opened file with the same filename\n",
    "    except:\n",
    "        return\n",
    "    dateparse = lambda dates: [datetime.strptime(str(d), '%Y%m%d') for d in dates] # function for parsing the dates from the txt, for each column in a row the value is converted to a string and parsed into a datetime object\n",
    "    df_station_desc = pd.read_fwf(stations_fname, skiprows = 2, header=None, parse_dates = [1,2], date_parser = dateparse, encoding = 'latin-1') # encoding of txt is ISO-8859-1/latin (german umlaute)\n",
    "    # Read the table of fixed-width formatted lines from stations_fname file into DataFrame, skipping 2 rows, do not set a header, so that indeces are used, the columns 1 \"von_datum\" and 2 \"bis_datum\" are parsed as dates with the function dateparse\n",
    "    df_station_desc.columns = [\"station_id\", \"date_from\", \"date_to\", \"altitude\", \"latitude\", \"longitude\",\"name\", \"state\"] # english column names are set\n",
    "    df_station_desc.set_index(\"station_id\", inplace = True) # setting station_id column as index and replacing the standard numeration\n",
    "    df_station_desc_query = df_station_desc.query('state == @state & date_from <= @year_from & date_to >= @year_to')\n",
    "    df_station_desc_query.to_csv(\"df_station_desc_query.csv\")\n",
    "    return df_station_desc_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_ftp_dir_query(df_ftp_dir,df_station_desc_query):\n",
    "    stations = list(df_station_desc_query.index.values)\n",
    "    df_ftp_dir_query = df_ftp_dir.query('station_id == @stations')\n",
    "    df_ftp_dir_query.to_csv(\"df_ftp_dir_query.csv\")\n",
    "    return df_ftp_dir_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stations(df_station_desc_query):\n",
    "    lst = []\n",
    "    stations = list(df_station_desc_query.index.values) \n",
    "    dateparse = lambda dates: [pd.to_datetime(d, yearfirst = True) for d in dates]\n",
    "    date1 = pd.to_datetime(str(years[0])+\"1231\", yearfirst = True)\n",
    "    date2 = pd.to_datetime(str(years[1])+\"1231\", yearfirst = True)\n",
    "    date3 = pd.to_datetime(str(years[2])+\"1231\", yearfirst = True)\n",
    "    for st_id in stations:\n",
    "        f_name = df_ftp_dir.loc[st_id,\"fname\"]\n",
    "        p_name = df_ftp_dir.loc[st_id,\"pname\"]\n",
    "        ftp.retrbinary('RETR ' + f_name, open( f_name, 'wb').write) \n",
    "\n",
    "        with ZipFile(f_name) as myzip:\n",
    "            with myzip.open(p_name) as myfile:\n",
    "                df_f = pd.read_csv(myfile, delimiter=\";\", encoding=\"utf8\", parse_dates = [\"MESS_DATUM_BEGINN\", \"MESS_DATUM_ENDE\"], date_parser = dateparse, na_values = [-999])\n",
    "                # df_f.dropna(subset=[\"JA_TT\"])\n",
    "                altitude = df_station_desc_query.loc[st_id, \"altitude\"]\n",
    "                latitude = df_station_desc_query.loc[st_id, \"latitude\"]\n",
    "                longitude = df_station_desc_query.loc[st_id, \"longitude\"]\n",
    "                name = df_station_desc_query.loc[st_id, \"name\"]\n",
    "                if df_f.query('MESS_DATUM_ENDE == @date1')[\"JA_TT\"].values.size > 0:\n",
    "                    yat_2017 = df_f.query('MESS_DATUM_ENDE == @date1')[\"JA_TT\"].values[0]\n",
    "                else: yat_2017 = np.NaN\n",
    "                if df_f.query('MESS_DATUM_ENDE == @date2')[\"JA_TT\"].values.size > 0:\n",
    "                    yat_2018 = df_f.query('MESS_DATUM_ENDE == @date2')[\"JA_TT\"].values[0]\n",
    "                else: yat_2018 = np.NaN\n",
    "                if df_f.query('MESS_DATUM_ENDE == @date3')[\"JA_TT\"].values.size > 0:\n",
    "                    yat_2019 = df_f.query('MESS_DATUM_ENDE == @date3')[\"JA_TT\"].values[0]\n",
    "                else: yat_2019 = np.NaN\n",
    "                '''\n",
    "                debugging/finding reason for empty values\n",
    "                print(\"---------------\")\n",
    "                print(st_id)\n",
    "                print(df_f.query('MESS_DATUM_ENDE == @date1')[\"JA_TT\"].values)\n",
    "                print(df_f.query('MESS_DATUM_ENDE == @date2')[\"JA_TT\"].values)\n",
    "                print(df_f.query('MESS_DATUM_ENDE == @date3')[\"JA_TT\"].values)\n",
    "                print(type(yat_2017))\n",
    "                print(type(yat_2018))\n",
    "                print(type(yat_2019))\n",
    "                print(yat_2017)\n",
    "                print(yat_2018)\n",
    "                print(yat_2019)\n",
    "                '''\n",
    "                lst.append([st_id, altitude, latitude, longitude, name, yat_2017, yat_2018, yat_2019])\n",
    "\n",
    "                # dftmp.merge(df_stations,how=\"inner\",left_on=\"stations_id\",right_on=\"station_id\",right_index=True)\n",
    "                # df = pd.merge(df, s, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "    df = pd.DataFrame(lst, columns=[\"station_id\", \"altitude\", \"latitude\", \"longitude\", \"name\", \"yat_2017\", \"yat_2018\", \"yat_2019\"])\n",
    "    #df = df.dropna() # some values are not present for a single year, uncomment this line to only show stations with data for each year in the selection\n",
    "    df.set_index(\"station_id\", inplace = True) # setting station_id column as index and replacing the standard numeration\n",
    "    df.to_csv(\"df_all.csv\")\n",
    "    return df"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def plot(df):\n",
    "\n",
    "    df_corr = pd.DataFrame(df_appended_ts.loc[:,o2])\n",
    "    df_corr[o1] = df_appended_ts.loc[:,o1]\n",
    "    Y = df_appended_ts.loc[:,o1].values.reshape(-1, 1)\n",
    "    X = df_appended_ts.loc[:,o2].values.reshape(-1, 1)\n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    score = linear_regressor.score(X, Y)\n",
    "    Y_pred = linear_regressor.predict(X)\n",
    "\n",
    "    \n",
    "    fig1, ax1 = plt.subplots(dpi=136, figsize=(8,6))\n",
    "    b = round((linear_regressor.intercept_[0]),4)\n",
    "    m = round((linear_regressor.coef_[0][0]),4)\n",
    "    sx = 0.35 * ax1.get_xlim()[1]\n",
    "    sy = 1.69 * ax1.get_ylim()[0]\n",
    "    r = round(score,4)\n",
    "    ax1.plot(X, Y_pred, color='red')\n",
    "    ax1.plot(df_plot[o2],df_plot[o1],\".\")\n",
    "    ax1.set_ylabel(po1)\n",
    "    ax1.set_xlabel(po2)\n",
    "    ax1.set_title(po1+\" vs. \"+po2+\" in Year \" + year_selected + \" at DWD Stations in \" + state+\"\\ny=\"+str(m)+\"*x+\"+str(b)+\", R^2= \"+str(r))\n",
    "\n",
    "    #ax1.text(x=sx,y=sy,s=(\"y=\"+str(m)+\"*x + \"+str(b)+\", R^2= \"+str(r)))\n",
    "\n",
    "    ax1.grid(True)\n",
    "    plt.show()\n",
    "    fig1.savefig(fpo1+\"_\"+fpo2+\"_\"+year_selected+\"_DWD_Stations_\"+state+\".png\")\n",
    "    print(\"A low R^2 value indicates, that the regression model is not fitting well (no strong correlation of data points).\\n\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Main run function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "    print(\"connecting...\")\n",
    "    ftp = connect_ftp()\n",
    "    print(\"accessing ftp...\")\n",
    "    df_ftp_dir = gen_df_ftp_dir()\n",
    "    print(\"query...\")\n",
    "    df_station_desc_query = gen_df_station_desc_query()\n",
    "    df_ftp_dir_query = gen_df_ftp_dir_query(df_ftp_dir,df_station_desc_query)\n",
    "    print(\"downloading...\")\n",
    "    df_all = download_stations(df_station_desc_query)\n",
    "    #plot(df_all)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "connecting...\n",
      "accessing ftp...\n",
      "query...\n",
      "downloading...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      fname  \\\n",
       "station_id                                                    \n",
       "1           jahreswerte_KL_00001_19310101_19851231_hist.zip   \n",
       "3           jahreswerte_KL_00003_18510101_20101231_hist.zip   \n",
       "44          jahreswerte_KL_00044_19720101_20191231_hist.zip   \n",
       "52          jahreswerte_KL_00052_19730101_20011231_hist.zip   \n",
       "61          jahreswerte_KL_00061_19760101_19771231_hist.zip   \n",
       "...                                                     ...   \n",
       "15963       jahreswerte_KL_15963_19530101_20031231_hist.zip   \n",
       "15965       jahreswerte_KL_15965_19700101_19831231_hist.zip   \n",
       "15979       jahreswerte_KL_15979_19480101_19781231_hist.zip   \n",
       "16085       jahreswerte_KL_16085_19610101_19611231_hist.zip   \n",
       "19087       jahreswerte_KL_19087_19580101_19941231_hist.zip   \n",
       "\n",
       "                                                     pname  \n",
       "station_id                                                  \n",
       "1           produkt_klima_jahr_19310101_19851231_00001.txt  \n",
       "3           produkt_klima_jahr_18510101_20101231_00003.txt  \n",
       "44          produkt_klima_jahr_19720101_20191231_00044.txt  \n",
       "52          produkt_klima_jahr_19730101_20011231_00052.txt  \n",
       "61          produkt_klima_jahr_19760101_19771231_00061.txt  \n",
       "...                                                    ...  \n",
       "15963       produkt_klima_jahr_19530101_20031231_15963.txt  \n",
       "15965       produkt_klima_jahr_19700101_19831231_15965.txt  \n",
       "15979       produkt_klima_jahr_19480101_19781231_15979.txt  \n",
       "16085       produkt_klima_jahr_19610101_19611231_16085.txt  \n",
       "19087       produkt_klima_jahr_19580101_19941231_19087.txt  \n",
       "\n",
       "[1076 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>pname</th>\n    </tr>\n    <tr>\n      <th>station_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>jahreswerte_KL_00001_19310101_19851231_hist.zip</td>\n      <td>produkt_klima_jahr_19310101_19851231_00001.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>jahreswerte_KL_00003_18510101_20101231_hist.zip</td>\n      <td>produkt_klima_jahr_18510101_20101231_00003.txt</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>jahreswerte_KL_00044_19720101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_19720101_20191231_00044.txt</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>jahreswerte_KL_00052_19730101_20011231_hist.zip</td>\n      <td>produkt_klima_jahr_19730101_20011231_00052.txt</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>jahreswerte_KL_00061_19760101_19771231_hist.zip</td>\n      <td>produkt_klima_jahr_19760101_19771231_00061.txt</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15963</th>\n      <td>jahreswerte_KL_15963_19530101_20031231_hist.zip</td>\n      <td>produkt_klima_jahr_19530101_20031231_15963.txt</td>\n    </tr>\n    <tr>\n      <th>15965</th>\n      <td>jahreswerte_KL_15965_19700101_19831231_hist.zip</td>\n      <td>produkt_klima_jahr_19700101_19831231_15965.txt</td>\n    </tr>\n    <tr>\n      <th>15979</th>\n      <td>jahreswerte_KL_15979_19480101_19781231_hist.zip</td>\n      <td>produkt_klima_jahr_19480101_19781231_15979.txt</td>\n    </tr>\n    <tr>\n      <th>16085</th>\n      <td>jahreswerte_KL_16085_19610101_19611231_hist.zip</td>\n      <td>produkt_klima_jahr_19610101_19611231_16085.txt</td>\n    </tr>\n    <tr>\n      <th>19087</th>\n      <td>jahreswerte_KL_19087_19580101_19941231_hist.zip</td>\n      <td>produkt_klima_jahr_19580101_19941231_19087.txt</td>\n    </tr>\n  </tbody>\n</table>\n<p>1076 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_ftp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      fname  \\\n",
       "station_id                                                    \n",
       "73          jahreswerte_KL_00073_19530101_20191231_hist.zip   \n",
       "142         jahreswerte_KL_00142_19550101_20191231_hist.zip   \n",
       "151         jahreswerte_KL_00151_18810101_20191231_hist.zip   \n",
       "154         jahreswerte_KL_00154_19940101_20191231_hist.zip   \n",
       "191         jahreswerte_KL_00191_18840101_20191231_hist.zip   \n",
       "...                                                     ...   \n",
       "7412        jahreswerte_KL_07412_20070101_20191231_hist.zip   \n",
       "7424        jahreswerte_KL_07424_20070101_20191231_hist.zip   \n",
       "7431        jahreswerte_KL_07431_20080101_20191231_hist.zip   \n",
       "13710       jahreswerte_KL_13710_20090101_20191231_hist.zip   \n",
       "15555       jahreswerte_KL_15555_20170101_20191231_hist.zip   \n",
       "\n",
       "                                                     pname  \n",
       "station_id                                                  \n",
       "73          produkt_klima_jahr_19530101_20191231_00073.txt  \n",
       "142         produkt_klima_jahr_19550101_20191231_00142.txt  \n",
       "151         produkt_klima_jahr_18810101_20191231_00151.txt  \n",
       "154         produkt_klima_jahr_19940101_20191231_00154.txt  \n",
       "191         produkt_klima_jahr_18840101_20191231_00191.txt  \n",
       "...                                                    ...  \n",
       "7412        produkt_klima_jahr_20070101_20191231_07412.txt  \n",
       "7424        produkt_klima_jahr_20070101_20191231_07424.txt  \n",
       "7431        produkt_klima_jahr_20080101_20191231_07431.txt  \n",
       "13710       produkt_klima_jahr_20090101_20191231_13710.txt  \n",
       "15555       produkt_klima_jahr_20170101_20191231_15555.txt  \n",
       "\n",
       "[102 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>pname</th>\n    </tr>\n    <tr>\n      <th>station_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>73</th>\n      <td>jahreswerte_KL_00073_19530101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_19530101_20191231_00073.txt</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>jahreswerte_KL_00142_19550101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_19550101_20191231_00142.txt</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>jahreswerte_KL_00151_18810101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_18810101_20191231_00151.txt</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>jahreswerte_KL_00154_19940101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_19940101_20191231_00154.txt</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>jahreswerte_KL_00191_18840101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_18840101_20191231_00191.txt</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7412</th>\n      <td>jahreswerte_KL_07412_20070101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_20070101_20191231_07412.txt</td>\n    </tr>\n    <tr>\n      <th>7424</th>\n      <td>jahreswerte_KL_07424_20070101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_20070101_20191231_07424.txt</td>\n    </tr>\n    <tr>\n      <th>7431</th>\n      <td>jahreswerte_KL_07431_20080101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_20080101_20191231_07431.txt</td>\n    </tr>\n    <tr>\n      <th>13710</th>\n      <td>jahreswerte_KL_13710_20090101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_20090101_20191231_13710.txt</td>\n    </tr>\n    <tr>\n      <th>15555</th>\n      <td>jahreswerte_KL_15555_20170101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_20170101_20191231_15555.txt</td>\n    </tr>\n  </tbody>\n</table>\n<p>102 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_ftp_dir_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            date_from    date_to  altitude  latitude  longitude  \\\n",
       "station_id                                                        \n",
       "73         1953-01-01 2020-12-31       340   48.6159    13.0506   \n",
       "142        1955-01-01 2020-12-31       511   48.4060    11.3117   \n",
       "151        1881-01-01 2020-12-31       382   49.4691    11.8546   \n",
       "154        1994-01-01 2020-12-31       516   48.0197    12.2925   \n",
       "191        1884-01-01 2020-12-31       217   49.9694     9.9114   \n",
       "...               ...        ...       ...       ...        ...   \n",
       "7412       2006-10-01 2020-12-31       340   50.0083     9.4238   \n",
       "7424       2007-01-01 2020-12-31       457   47.7724    12.9073   \n",
       "7431       2008-01-01 2020-12-31       604   48.0130    11.5524   \n",
       "13710      2009-01-01 2020-12-31       490   48.5734    12.2576   \n",
       "15555      2017-01-01 2020-12-31       815   47.8761    10.5849   \n",
       "\n",
       "                               name   state  \n",
       "station_id                                   \n",
       "73             Aldersbach-Kriestorf  Bayern  \n",
       "142           Altomünster-Maisbrunn  Bayern  \n",
       "151         Amberg-Unterammersricht  Bayern  \n",
       "154                Amerang-Pfaffing  Bayern  \n",
       "191              Arnstein-Müdesheim  Bayern  \n",
       "...                             ...     ...  \n",
       "7412             Neuhütten/Spessart  Bayern  \n",
       "7424                         Piding  Bayern  \n",
       "7431           Oberhaching-Laufzorn  Bayern  \n",
       "13710              Landshut-Reithof  Bayern  \n",
       "15555         Kaufbeuren-Oberbeuren  Bayern  \n",
       "\n",
       "[102 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_from</th>\n      <th>date_to</th>\n      <th>altitude</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>name</th>\n      <th>state</th>\n    </tr>\n    <tr>\n      <th>station_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>73</th>\n      <td>1953-01-01</td>\n      <td>2020-12-31</td>\n      <td>340</td>\n      <td>48.6159</td>\n      <td>13.0506</td>\n      <td>Aldersbach-Kriestorf</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>1955-01-01</td>\n      <td>2020-12-31</td>\n      <td>511</td>\n      <td>48.4060</td>\n      <td>11.3117</td>\n      <td>Altomünster-Maisbrunn</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>1881-01-01</td>\n      <td>2020-12-31</td>\n      <td>382</td>\n      <td>49.4691</td>\n      <td>11.8546</td>\n      <td>Amberg-Unterammersricht</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>1994-01-01</td>\n      <td>2020-12-31</td>\n      <td>516</td>\n      <td>48.0197</td>\n      <td>12.2925</td>\n      <td>Amerang-Pfaffing</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>1884-01-01</td>\n      <td>2020-12-31</td>\n      <td>217</td>\n      <td>49.9694</td>\n      <td>9.9114</td>\n      <td>Arnstein-Müdesheim</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7412</th>\n      <td>2006-10-01</td>\n      <td>2020-12-31</td>\n      <td>340</td>\n      <td>50.0083</td>\n      <td>9.4238</td>\n      <td>Neuhütten/Spessart</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>7424</th>\n      <td>2007-01-01</td>\n      <td>2020-12-31</td>\n      <td>457</td>\n      <td>47.7724</td>\n      <td>12.9073</td>\n      <td>Piding</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>7431</th>\n      <td>2008-01-01</td>\n      <td>2020-12-31</td>\n      <td>604</td>\n      <td>48.0130</td>\n      <td>11.5524</td>\n      <td>Oberhaching-Laufzorn</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>13710</th>\n      <td>2009-01-01</td>\n      <td>2020-12-31</td>\n      <td>490</td>\n      <td>48.5734</td>\n      <td>12.2576</td>\n      <td>Landshut-Reithof</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>15555</th>\n      <td>2017-01-01</td>\n      <td>2020-12-31</td>\n      <td>815</td>\n      <td>47.8761</td>\n      <td>10.5849</td>\n      <td>Kaufbeuren-Oberbeuren</td>\n      <td>Bayern</td>\n    </tr>\n  </tbody>\n</table>\n<p>102 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_station_desc_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            altitude  latitude  longitude                     name  yat_2017  \\\n",
       "station_id                                                                     \n",
       "73               340   48.6159    13.0506     Aldersbach-Kriestorf      9.38   \n",
       "142              511   48.4060    11.3117    Altomünster-Maisbrunn      9.19   \n",
       "151              382   49.4691    11.8546  Amberg-Unterammersricht      9.30   \n",
       "154              516   48.0197    12.2925         Amerang-Pfaffing      8.91   \n",
       "191              217   49.9694     9.9114       Arnstein-Müdesheim      9.61   \n",
       "...              ...       ...        ...                      ...       ...   \n",
       "7412             340   50.0083     9.4238       Neuhütten/Spessart      8.98   \n",
       "7424             457   47.7724    12.9073                   Piding      8.94   \n",
       "7431             604   48.0130    11.5524     Oberhaching-Laufzorn      8.72   \n",
       "13710            490   48.5734    12.2576         Landshut-Reithof      9.58   \n",
       "15555            815   47.8761    10.5849    Kaufbeuren-Oberbeuren      8.51   \n",
       "\n",
       "            yat_2018  yat_2019  \n",
       "station_id                      \n",
       "73             10.73     10.16  \n",
       "142            10.16      9.81  \n",
       "151            10.39     10.09  \n",
       "154             9.98      9.57  \n",
       "191            10.58     10.19  \n",
       "...              ...       ...  \n",
       "7412           10.04      9.64  \n",
       "7424            9.91      9.69  \n",
       "7431            9.60      9.06  \n",
       "13710          10.61     10.33  \n",
       "15555           9.42      8.99  \n",
       "\n",
       "[102 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>altitude</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>name</th>\n      <th>yat_2017</th>\n      <th>yat_2018</th>\n      <th>yat_2019</th>\n    </tr>\n    <tr>\n      <th>station_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>73</th>\n      <td>340</td>\n      <td>48.6159</td>\n      <td>13.0506</td>\n      <td>Aldersbach-Kriestorf</td>\n      <td>9.38</td>\n      <td>10.73</td>\n      <td>10.16</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>511</td>\n      <td>48.4060</td>\n      <td>11.3117</td>\n      <td>Altomünster-Maisbrunn</td>\n      <td>9.19</td>\n      <td>10.16</td>\n      <td>9.81</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>382</td>\n      <td>49.4691</td>\n      <td>11.8546</td>\n      <td>Amberg-Unterammersricht</td>\n      <td>9.30</td>\n      <td>10.39</td>\n      <td>10.09</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>516</td>\n      <td>48.0197</td>\n      <td>12.2925</td>\n      <td>Amerang-Pfaffing</td>\n      <td>8.91</td>\n      <td>9.98</td>\n      <td>9.57</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>217</td>\n      <td>49.9694</td>\n      <td>9.9114</td>\n      <td>Arnstein-Müdesheim</td>\n      <td>9.61</td>\n      <td>10.58</td>\n      <td>10.19</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7412</th>\n      <td>340</td>\n      <td>50.0083</td>\n      <td>9.4238</td>\n      <td>Neuhütten/Spessart</td>\n      <td>8.98</td>\n      <td>10.04</td>\n      <td>9.64</td>\n    </tr>\n    <tr>\n      <th>7424</th>\n      <td>457</td>\n      <td>47.7724</td>\n      <td>12.9073</td>\n      <td>Piding</td>\n      <td>8.94</td>\n      <td>9.91</td>\n      <td>9.69</td>\n    </tr>\n    <tr>\n      <th>7431</th>\n      <td>604</td>\n      <td>48.0130</td>\n      <td>11.5524</td>\n      <td>Oberhaching-Laufzorn</td>\n      <td>8.72</td>\n      <td>9.60</td>\n      <td>9.06</td>\n    </tr>\n    <tr>\n      <th>13710</th>\n      <td>490</td>\n      <td>48.5734</td>\n      <td>12.2576</td>\n      <td>Landshut-Reithof</td>\n      <td>9.58</td>\n      <td>10.61</td>\n      <td>10.33</td>\n    </tr>\n    <tr>\n      <th>15555</th>\n      <td>815</td>\n      <td>47.8761</td>\n      <td>10.5849</td>\n      <td>Kaufbeuren-Oberbeuren</td>\n      <td>8.51</td>\n      <td>9.42</td>\n      <td>8.99</td>\n    </tr>\n  </tbody>\n</table>\n<p>102 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "source": [
    "df.replace(to_replace = -999,value = (np.nan),inplace=True)\n",
    "df = df.dropna(subset = [(str(o1)),(str(o2))])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}