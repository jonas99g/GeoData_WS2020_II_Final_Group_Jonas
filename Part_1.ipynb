{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Part 1 Correlation of Mean Annual Temperature with Altitude in Bavaria\n",
    "In the first lectures we analysed the annual temperature in NRW by means of long time series. The observed temperature increase particularly in the last decade is most likely an indication of climate. We also observed that the station \"Kahler Asten\" shows systematic lower temperatures than other stations. We presumed this being an effect of decreasing temperature with topographic height, since \"Kahler Asten\" is among the highest points in NRW. \n",
    "\n",
    "Verify this hypothesis by means of data in Bavaria. This federal state reveals the broadest range of topographic heights, from 100m to more than 2800m above Normal-Null (NN). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Task 1\n",
    "Plot the annual mean temperatures of **years 2017, 2018, and 2019** versus altitude for the DWD stations in Bavaria. At first use the **altitudes from the station description file** `KL_Jahreswerte_Beschreibung_Stationen.txt` for the data set `/annual/kl/historical/`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing necessary libaries for Part 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime # used for time format conversion\n",
    "import os # access to host system to create directories and write files\n",
    "import ftplib # libary to access ftp server\n",
    "import urllib3 \n",
    "import codecs\n",
    "from zipfile import ZipFile # used for unzipping zip files\n",
    "import numpy as np # for replacing bad values with true NotaNumber from numpy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# making plots available in jupyter output line\n",
    "import pandas as pd # for pandas dataframe to read csv\n",
    "pd.options.display.max_seq_items = None # pandas printing options\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression # linear regression to calculate a trendline from data points, Task 4"
   ]
  },
  {
   "source": [
    "## Defining variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_server = \"opendata.dwd.de\" # root of file server\n",
    "ftp_user = \"anonymous\"\n",
    "ftp_passwd = \"\"\n",
    "ftp_dir =  \"/climate_environment/CDC/observations_germany/climate/annual/kl/historical/\" # directory\n",
    "state = \"Bayern\" # Selected state to filter\n",
    "years = [2017, 2018, 2019] # selected years\n",
    "nyears = len(years) # length of years list\n",
    "year_from = datetime.strptime(str(years[0])+\"0101\", '%Y%m%d') # lowest year from the list\n",
    "year_to = datetime.strptime(str(years[nyears-1])+\"1231\", '%Y%m%d') # highest year from the list\n",
    "stations_fname = \"\" # initializing variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_ftp(): # establishing connection to ftp server and check if it was successfull\n",
    "    ftp = ftplib.FTP(ftp_server) # creating ftp server instance\n",
    "    res = ftp.login(user = ftp_user, passwd = ftp_passwd) # logging in to server\n",
    "    ret = ftp.cwd(ftp_dir) # Changing into correct ftp directory\n",
    "    return ftp # return configured and connected ftp instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_ftp_dir():\n",
    "    lines = [] # buffer for storing lines of ftp directory\n",
    "    flist = [] # buffer for temporarily storing station_idm, zip file names and product file name\n",
    "    try:\n",
    "        res = ftp.retrlines(\"NLST\", lines.append) # retrieve lines with NLST ftp command, which lsits file names including extention, the returned lines are appended to the lines buffer\n",
    "    except:\n",
    "        return\n",
    "    global stations_fname # setting global variable to use filename later\n",
    "    stations_fname = lines[0] # storing first line, which is the file name of the station description\n",
    "    lines.pop(0) # removing station description file from buffer to read only zip files later\n",
    "    for line in lines: # looping through elements of the lines buffer\n",
    "        pname = \"produkt_klima_jahr_\"+line.split(\"_\")[3]+\"_\"+line.split(\"_\")[4]+\"_\"+line.split(\"_\")[2]+\".txt\" # generating product file name\n",
    "        flist.append([int(line.split(\"_\")[2]), line, pname]) # reading variables into temporary list\n",
    "    df_ftp_dir = pd.DataFrame(flist,columns=[\"station_id\", \"fname\", \"pname\"]) # creating a pandas dataframe from flist, defining column names for elements in the list\n",
    "    df_ftp_dir.set_index(\"station_id\", inplace = True) # setting station_id column as index and replacing the standard numeration\n",
    "    return df_ftp_dir # return the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_station_desc():\n",
    "    try:\n",
    "        ftp.retrbinary('RETR '+ stations_fname, open(stations_fname, 'wb').write) # retrieve the binary code from the stations_fname file from ftp and writing to a newly opened file with the same filename\n",
    "    except:\n",
    "        return\n",
    "    dateparse = lambda dates: [datetime.strptime(str(d), '%Y%m%d') for d in dates] # function for parsing the dates from the txt, for each column in a row the value is converted to a string and parsed into a datetime object\n",
    "    df_station_desc = pd.read_fwf(stations_fname, skiprows = 2, header=None, parse_dates = [1,2], date_parser = dateparse) # encoding=\"utf8\", \n",
    "    # Read the table of fixed-width formatted lines from stations_fname file into DataFrame, skipping 2 rows, do not set a header, so that indeces are used, the columns 1 \"von_datum\" and 2 \"bis_datum\" are parsed as dates with the function dateparse\n",
    "    df_station_desc.columns = [\"station_id\", \"date_from\", \"date_to\", \"altitude\", \"latitude\", \"longitude\",\"name\", \"state\"] # english column names are set\n",
    "    df_station_desc.set_index(\"station_id\", inplace = True) # setting station_id column as index and replacing the standard numeration\n",
    "    return df_station_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_stations(st_id):#, year):\n",
    "\n",
    "    f_name = df_ftp_dir[\"station_id\" == st_id][\"fname\"] # id from function, selecting corresponding row from ftp directory dataframe and the \"fname\" column and returning the value\n",
    "    p_name = df_ftp_dir[\"station_id\" == st_id][\"pname\"] # id from function, selecting corresponding row from ftp directory dataframe and the \"pname\" column and returning the value\n",
    "    try:\n",
    "        ftp.retrbinary('RETR ' + f_name, open( fname, 'wb').write) # retrieve the binary code from the fname zip file from ftp and writing to a newly opened file with the same filename\n",
    "    except:\n",
    "        return\n",
    "    with ZipFile(f_name) as myzip: # recently downloaded file is initialized as ZipFile\n",
    "        with myzip.open(p_name) as myfile: # zip file is opened and the containing product file is opened as myfile \n",
    "            df = pd.read_csv(myfile)\n",
    "            print(df)\n",
    "        \n",
    "        '''\n",
    "        with ZipFile(fname, 'r') as zipObj:\n",
    "            zipObj.extract(pname, 'temp_csv')\n",
    "        \n",
    "        fname.unzip(pname)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stations():\n",
    "    global local_zip_list\n",
    "    local_zip_list = []\n",
    "    for station_id in station_ids_selected:\n",
    "        try:\n",
    "            fname = df_zips[\"name\"][station_id]\n",
    "            grabFile(ftp_dir + fname, local_ftp_ts_dir + fname)\n",
    "            local_p_list.append(fname)\n",
    "        except:\n",
    "            (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_ts_to_df(fname): \n",
    "    dateparse = lambda dates: [datetime.strptime(str(d), '%Y%m%d') for d in dates]\n",
    "    df = pd.read_csv(fname, delimiter=\";\", encoding=\"utf8\", index_col=\"MESS_DATUM_BEGINN\", parse_dates = [\"MESS_DATUM_BEGINN\", \"MESS_DATUM_ENDE\"], date_parser = dateparse, na_values = [-999.0, -999])\n",
    "    df = df[(df.index >= date_from) & (df.index <= date_to)]\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "    df.index.name = df.index.name.strip().lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_merge():\n",
    "    df = pd.DataFrame()\n",
    "    for elt in local_zip_list:\n",
    "        ffname = local_ftp_ts_dir + elt\n",
    "        with ZipFile(ffname) as myzip:\n",
    "            # read the time series data from the file starting with \"produkt\"\n",
    "            prodfilename = [elt for elt in myzip.namelist() if elt.split(\"_\")[0]==\"produkt\"][0] \n",
    "            with myzip.open(prodfilename) as myfile:\n",
    "                dftmp = kl_ts_to_df(myfile)\n",
    "                if len(dftmp) > 0:\n",
    "                    s = dftmp[\"ja_tt\"].rename(dftmp[\"stations_id\"][0]).to_frame()\n",
    "                    df = pd.merge(df, s, left_index=True, right_index=True, how='outer')\n",
    "                else:\n",
    "                    (\"\")\n",
    "    df = df.dropna(axis='columns')\n",
    "    df.index.rename(name = \"time\", inplace = True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_append():\n",
    "    df = pd.DataFrame()\n",
    "    for elt in local_zip_list:\n",
    "        ffname = local_ftp_ts_dir + elt\n",
    "        with ZipFile(ffname) as myzip:\n",
    "            prodfilename = [elt for elt in myzip.namelist() if elt.split(\"_\")[0]==\"produkt\"][0]\n",
    "            with myzip.open(prodfilename) as myfile:\n",
    "                dftmp = kl_ts_to_df(myfile)\n",
    "                if len(dftmp) > 0:\n",
    "                    dftmp = dftmp.merge(df_stations,how=\"inner\",left_on=\"stations_id\",right_on=\"station_id\",right_index=True)\n",
    "                    df = df.append(dftmp)\n",
    "                else:\n",
    "                    (\"\")\n",
    "    df.index.rename(name = \"time\", inplace = True)\n",
    "    \n",
    "    df.replace(to_replace = -999,value = (np.nan),inplace=True)\n",
    "    \n",
    "    df = df.dropna(subset = [(str(o1)),(str(o2))])\n",
    "    \n",
    "    #ind1 = df[df[str(o1)]==-999].index\n",
    "    #df.drop(ind1,inplace=True)\n",
    "    #ind2 = df[df[str(o2)]==-999].index\n",
    "    #df.drop(ind2,inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    retranslate = {\"ja_tt\":\"Average Temperature\",\"ja_tx\":\"Yearly Average Max Temperature\",\"ja_tn\":\"Yearly Average Min Temperature\",\"ja_fk\":\"Average Windforce\",\"ja_sd_s\":\"Sum Yearly Sunshine Duration\",\"ja_mx_tx\":\"Absolute Max Temperature\",\"ja_mx_tn\":\"Absolute Min Temperature\",\"ja_rr\":\"Sum Yearly Precipitation\",\"ja_mx_rs\":\"Max Precipitation Height\",\"altitude\":\"Altitude\",\"latitude\":\"Latitude\",\"longitude\":\"Longitude\"}\n",
    "    po1 = retranslate[(o1)]\n",
    "    po2 = retranslate[(o2)]\n",
    "    fpo1 = po1.replace(\" \", \"_\")\n",
    "    fpo2 = po2.replace(\" \", \"_\")\n",
    "\n",
    "    df_plot = df_appended_ts\n",
    "    \n",
    "    df_corr = pd.DataFrame(df_appended_ts.loc[:,o2])\n",
    "    df_corr[o1] = df_appended_ts.loc[:,o1]\n",
    "    Y = df_appended_ts.loc[:,o1].values.reshape(-1, 1)\n",
    "    X = df_appended_ts.loc[:,o2].values.reshape(-1, 1)\n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X, Y)\n",
    "    score = linear_regressor.score(X, Y)\n",
    "    Y_pred = linear_regressor.predict(X)\n",
    "\n",
    "    \n",
    "    fig1, ax1 = plt.subplots(dpi=136, figsize=(8,6))\n",
    "    b = round((linear_regressor.intercept_[0]),4)\n",
    "    m = round((linear_regressor.coef_[0][0]),4)\n",
    "    sx = 0.35 * ax1.get_xlim()[1]\n",
    "    sy = 1.69 * ax1.get_ylim()[0]\n",
    "    r = round(score,4)\n",
    "    ax1.plot(X, Y_pred, color='red')\n",
    "    ax1.plot(df_plot[o2],df_plot[o1],\".\")\n",
    "    ax1.set_ylabel(po1)\n",
    "    ax1.set_xlabel(po2)\n",
    "    ax1.set_title(po1+\" vs. \"+po2+\" in Year \" + year_selected + \" at DWD Stations in \" + state+\"\\ny=\"+str(m)+\"*x+\"+str(b)+\", R^2= \"+str(r))\n",
    "\n",
    "    #ax1.text(x=sx,y=sy,s=(\"y=\"+str(m)+\"*x + \"+str(b)+\", R^2= \"+str(r)))\n",
    "\n",
    "    ax1.grid(True)\n",
    "    plt.show()\n",
    "    fig1.savefig(fpo1+\"_\"+fpo2+\"_\"+year_selected+\"_DWD_Stations_\"+state+\".png\")\n",
    "    print(\"A low R^2 value indicates, that the regression model is not fitting well (no strong correlation of data points).\\n\")"
   ]
  },
  {
   "source": [
    "## Main run function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading...\\n\")\n",
    "process()\n",
    "print(\"Plotting...\\n\")\n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    ftp = connect_ftp()\n",
    "    df_ftp_dir = gen_df_ftp_dir()\n",
    "    df_station_desc = gen_df_station_desc()\n",
    "    station_ids_selected = []\n",
    "    grab_stations(station_ids_selected)\n",
    "\n",
    "    download_stations()\n",
    "    global df_merged_ts\n",
    "    df_merged_ts = ts_merge()\n",
    "    df_merged_ts.to_csv(local_ts_merged_dir + \"ts_merged.csv\",sep=\";\")\n",
    "    global df_appended_ts = ts_append()\n",
    "    df_appended_ts.to_csv(local_ts_appended_dir + \"ts_appended.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xfc in position 320: invalid start byte",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-63bb6c8994d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mftp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_ftp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_ftp_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_df_ftp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_station_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_df_station_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstation_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_station_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'state == @state & date_from <= @year_from & date_to >= @year_to'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#for el in station_query[\"station_id\"]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-83f86fd90247>\u001b[0m in \u001b[0;36mgen_df_station_desc\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdateparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y%m%d'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# function for parsing the dates from the txt, for each column in a row the value is converted to a string and parsed into a datetime object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf_station_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_fwf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstations_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdateparse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Read the table of fixed-width formatted lines from stations_fname file into DataFrame, skipping 2 rows, do not set a header, so that indeces are used, the columns 1 \"von_datum\" and 2 \"bis_datum\" are parsed as dates with the function dateparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdf_station_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"station_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"date_from\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"date_to\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"altitude\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"latitude\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"longitude\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# english column names are set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf_station_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"station_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# setting station_id column as index and replacing the standard numeration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_fwf\u001b[0;34m(filepath_or_buffer, colspecs, widths, infer_nrows, **kwds)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"infer_nrows\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_nrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"python-fwf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   3758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"colspecs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3759\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_nrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"infer_nrows\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3760\u001b[0;31m         \u001b[0mPythonParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2295\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"readline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2299\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_reader\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   3761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3763\u001b[0;31m         self.data = FixedWidthReader(\n\u001b[0m\u001b[1;32m   3764\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolspecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, colspecs, delimiter, comment, skiprows, infer_nrows)\u001b[0m\n\u001b[1;32m   3653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolspecs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             self.colspecs = self.detect_colspecs(\n\u001b[0m\u001b[1;32m   3656\u001b[0m                 \u001b[0minfer_nrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_nrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mdetect_colspecs\u001b[0;34m(self, infer_nrows, skiprows)\u001b[0m\n\u001b[1;32m   3719\u001b[0m         \u001b[0mdelimiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mfr\"\\{x}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3720\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"([^{delimiters}]+)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3721\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer_nrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEmptyDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No rows from which to infer column width\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mget_rows\u001b[0;34m(self, infer_nrows, skiprows)\u001b[0m\n\u001b[1;32m   3706\u001b[0m         \u001b[0mbuffer_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3707\u001b[0m         \u001b[0mdetect_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3708\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3709\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m                 \u001b[0mdetect_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xfc in position 320: invalid start byte"
     ]
    }
   ],
   "source": [
    "ftp = connect_ftp()\n",
    "df_ftp_dir = gen_df_ftp_dir()\n",
    "df_station_desc = gen_df_station_desc()\n",
    "station_query = df_station_desc.query('state == @state & date_from <= @year_from & date_to >= @year_to')\n",
    "#for el in station_query[\"station_id\"]:\n",
    "    #print(el)\n",
    "#grab_stations(\"000003\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    STATIONS_ID MESS_DATUM_BEGINN MESS_DATUM_ENDE  QN_4  JA_N  JA_TT  JA_TX  \\\n0             1        1931-01-01      1931-12-31     5   NaN   7.52    NaN   \n1             1        1932-01-01      1932-12-31     5   NaN   8.12    NaN   \n2             1        1933-01-01      1933-12-31     5   NaN   7.68    NaN   \n3             1        1934-01-01      1934-12-31     5   NaN   9.31    NaN   \n4             1        1935-01-01      1935-12-31     5   NaN   8.41    NaN   \n5             1        1936-01-01      1936-12-31     5   NaN   8.59    NaN   \n6             1        1937-01-01      1937-12-31     5  4.95   8.59  13.29   \n7             1        1938-01-01      1938-12-31     5  4.61   8.18  13.48   \n8             1        1939-01-01      1939-12-31     5  5.48   7.99  12.23   \n9             1        1940-01-01      1940-12-31     5  4.95   7.07  11.85   \n10            1        1941-01-01      1941-12-31     5  5.02   7.61  12.39   \n11            1        1942-01-01      1942-12-31     5  4.91   7.95  13.05   \n12            1        1943-01-01      1943-12-31     5  4.67   9.57  15.02   \n13            1        1944-01-01      1944-12-31     5  5.26   8.22  12.99   \n14            1        1947-01-01      1947-12-31     5  4.71   9.38  14.89   \n15            1        1948-01-01      1948-12-31     5  5.04   8.82  14.37   \n16            1        1949-01-01      1949-12-31     5  4.60   9.27  15.34   \n17            1        1950-01-01      1950-12-31     5  5.10   8.80  14.39   \n18            1        1951-01-01      1951-12-31     5  5.47   8.74  13.93   \n19            1        1952-01-01      1952-12-31     5  5.52   8.33  13.76   \n20            1        1953-01-01      1953-12-31     5  5.24   8.19  13.81   \n21            1        1954-01-01      1954-12-31     5  5.84   7.49  12.61   \n22            1        1955-01-01      1955-12-31     5  5.55   7.87  12.83   \n23            1        1956-01-01      1956-12-31     5  5.80   7.27  11.84   \n24            1        1957-01-01      1957-12-31     5  5.50   8.56  13.47   \n25            1        1958-01-01      1958-12-31     5  5.70   8.55  13.34   \n26            1        1959-01-01      1959-12-31     5  4.86   8.86  14.09   \n27            1        1960-01-01      1960-12-31     5  5.90   8.25  13.02   \n28            1        1961-01-01      1961-12-31     5  5.24   9.12  14.38   \n29            1        1962-01-01      1962-12-31     5  5.10   7.22  12.34   \n30            1        1963-01-01      1963-12-31     5  5.53   7.22  12.15   \n31            1        1964-01-01      1964-12-31     5  5.67   8.48  13.18   \n32            1        1965-01-01      1965-12-31     5  5.92   7.41  12.01   \n33            1        1966-01-01      1966-12-31     5  5.49   8.61  13.49   \n34            1        1967-01-01      1967-12-31     5  5.16   8.57  13.78   \n35            1        1968-01-01      1968-12-31     5  5.74   8.26  12.95   \n36            1        1969-01-01      1969-12-31     5  5.11   7.91  12.52   \n37            1        1970-01-01      1970-12-31     5  5.50   7.90  12.38   \n38            1        1971-01-01      1971-12-31     5  4.85   8.02  13.23   \n39            1        1972-01-01      1972-12-31     5  5.51   7.65  12.44   \n40            1        1973-01-01      1973-12-31     5  5.48   7.86  12.57   \n41            1        1974-01-01      1974-12-31     5  5.80   8.62  13.18   \n42            1        1975-01-01      1975-12-31     5  5.60   8.55  12.91   \n43            1        1976-01-01      1976-12-31     5  5.19   8.45  13.38   \n44            1        1977-01-01      1977-12-31     5  5.93   8.61  13.14   \n45            1        1978-01-01      1978-12-31     5  5.87   7.53  12.10   \n46            1        1979-01-01      1979-12-31     5  5.73   8.20  13.06   \n47            1        1980-01-01      1980-12-31     5  5.65   7.41  12.25   \n48            1        1981-01-01      1981-12-31    10  5.62   8.17  13.15   \n49            1        1982-01-01      1982-12-31    10  5.49   8.60  13.39   \n50            1        1983-01-01      1983-12-31    10  5.16   8.61  13.83   \n51            1        1984-01-01      1984-12-31    10  5.38   7.73  12.62   \n52            1        1985-01-01      1985-12-31    10  5.13   7.55  13.00   \n\n    JA_TN  JA_FK  JA_SD_S  JA_MX_FX  JA_MX_TX  JA_MX_TN  QN_6   JA_RR  \\\n0    2.53    NaN      NaN       NaN       NaN       NaN     5   799.3   \n1    3.21    NaN      NaN       NaN       NaN       NaN     5   640.4   \n2    2.55    NaN      NaN       NaN       NaN       NaN     5   750.1   \n3    3.78    NaN      NaN       NaN       NaN       NaN     5   638.8   \n4    3.13    NaN      NaN       NaN       NaN       NaN     5   824.7   \n5    3.88    NaN      NaN       NaN       NaN       NaN     5   891.5   \n6    4.64   1.70      NaN       NaN      32.8     -11.0     5   817.4   \n7    3.78   1.34      NaN       NaN      31.5     -14.0     5   766.5   \n8    4.24   1.49      NaN       NaN      29.4     -21.2     5  1072.3   \n9    2.91   1.34      NaN       NaN      28.8     -20.4     5   966.2   \n10   3.23   1.43      NaN       NaN      33.6     -18.0     5   636.0   \n11   3.39   1.36      NaN       NaN      31.6     -23.2     5   734.3   \n12   4.68   1.36      NaN       NaN      38.2     -12.2     5   487.8   \n13   4.09   1.49      NaN       NaN      35.0     -12.0     5     NaN   \n14   4.37   1.21      NaN       NaN      37.2     -19.0     5   520.6   \n15   4.13   1.08      NaN       NaN      30.6     -13.2     5   613.0   \n16   3.96   1.14      NaN       NaN      35.0     -14.8     5   505.0   \n17   4.00   0.95      NaN       NaN      35.0     -12.6     5   774.9   \n18   4.05   0.96      NaN       NaN      32.2      -8.8     5   688.3   \n19   3.76   1.23      NaN       NaN      36.2     -12.8     5   927.7   \n20   3.65   0.92      NaN       NaN      31.4     -17.8     5   606.8   \n21   3.39   1.28      NaN       NaN      31.0     -16.0     5   876.6   \n22   3.25   1.39      NaN       NaN      31.8     -13.4     5   800.1   \n23   2.65   1.35      NaN       NaN      29.8     -23.0     5   675.1   \n24   3.89   1.16      NaN       NaN      34.8     -15.2     5   670.0   \n25   3.75   1.19      NaN       NaN      32.7     -13.2     5   855.0   \n26   3.35   1.43      NaN       NaN      32.4     -16.2     5   704.0   \n27   3.21   1.44      NaN       NaN      29.4     -20.8     5   913.2   \n28   3.78   1.57      NaN       NaN      32.2     -13.0     5   693.1   \n29   1.88   1.81      NaN       NaN      32.2     -18.0     5   629.7   \n30   2.20   1.58      NaN       NaN      32.8     -24.0     5   827.8   \n31   3.34   1.59      NaN       NaN      33.6     -18.0     5   720.6   \n32   2.74   1.74      NaN       NaN      30.8     -16.4     5  1140.9   \n33   3.68   1.68      NaN       NaN      32.0     -21.0     5   892.8   \n34   3.32   1.75      NaN       NaN      32.2     -16.6     5   733.0   \n35   3.40   1.70      NaN       NaN      30.6     -23.4     5   849.0   \n36   3.33   1.77      NaN       NaN      31.6     -16.2     5   776.6   \n37   3.45   1.87      NaN       NaN      33.2     -14.6     5   851.6   \n38   2.92   1.74      NaN       NaN      32.8     -18.8     5   599.3   \n39   3.10   1.87      NaN       NaN      30.5     -13.5     5   777.8   \n40   3.20   1.90      NaN       NaN      30.0     -20.4     5   754.1   \n41   4.28   2.06      NaN       NaN      32.6      -8.4     5   771.1   \n42   4.37   2.07      NaN       NaN      31.0     -16.2     5   847.4   \n43   3.60   2.10      NaN       NaN      33.0     -17.0     5   618.6   \n44   4.25   2.18      NaN       NaN      33.2      -9.6     5   813.5   \n45   2.91   2.00      NaN       NaN      30.0     -14.8     5   888.8   \n46   3.45   1.95      NaN       NaN      32.0     -19.5     5   776.7   \n47   2.91   1.95      NaN       NaN      33.0     -16.0     5   774.3   \n48   3.43   1.90      NaN       NaN      31.2     -16.0    10   866.3   \n49   4.19   1.94      NaN       NaN      31.6     -14.8    10   874.0   \n50   3.95   2.11      NaN       NaN      37.0     -13.0    10   731.5   \n51   3.33   1.89      NaN       NaN      34.0     -11.4    10   670.6   \n52   2.69   1.93      NaN       NaN      34.2     -26.0    10   568.9   \n\n    JA_MX_RS  eor  \n0       33.5  eor  \n1       41.4  eor  \n2       42.2  eor  \n3       49.8  eor  \n4       26.4  eor  \n5       32.4  eor  \n6       39.1  eor  \n7       30.2  eor  \n8       36.2  eor  \n9       38.7  eor  \n10      24.1  eor  \n11      36.2  eor  \n12      22.0  eor  \n13      38.6  eor  \n14      30.8  eor  \n15      33.8  eor  \n16      29.4  eor  \n17      39.0  eor  \n18      28.6  eor  \n19      60.5  eor  \n20      41.7  eor  \n21      43.0  eor  \n22      49.8  eor  \n23      38.9  eor  \n24      32.8  eor  \n25      31.7  eor  \n26      45.5  eor  \n27      40.8  eor  \n28      23.7  eor  \n29      22.7  eor  \n30      46.6  eor  \n31      40.8  eor  \n32      65.0  eor  \n33      32.2  eor  \n34      25.0  eor  \n35      53.2  eor  \n36      31.8  eor  \n37      26.5  eor  \n38      47.6  eor  \n39      52.4  eor  \n40      47.5  eor  \n41      55.7  eor  \n42      70.5  eor  \n43      35.5  eor  \n44      31.2  eor  \n45      67.2  eor  \n46      26.8  eor  \n47      35.2  eor  \n48      29.6  eor  \n49      55.5  eor  \n50      34.0  eor  \n51      29.8  eor  \n52      21.7  eor  \n"
     ]
    }
   ],
   "source": [
    "dateparse = lambda dates: [datetime.strptime(str(d), '%Y%m%d') for d in dates]\n",
    "f_name = df_ftp_dir.loc[1,\"fname\"]\n",
    "p_name = df_ftp_dir.loc[1,\"pname\"]\n",
    "ftp.retrbinary('RETR ' + f_name, open( f_name, 'wb').write)\n",
    "with ZipFile(f_name) as myzip:\n",
    "    with myzip.open(p_name) as myfile:\n",
    "        df = pd.read_csv(myfile, delimiter=\";\", encoding=\"utf8\", parse_dates = [\"MESS_DATUM_BEGINN\", \"MESS_DATUM_ENDE\"], date_parser = dateparse, na_values = [-999.0, -999])\n",
    "        #print(df[\"JA_TT\"])\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      fname  \\\n",
       "station_id                                                    \n",
       "1           jahreswerte_KL_00001_19310101_19851231_hist.zip   \n",
       "3           jahreswerte_KL_00003_18510101_20101231_hist.zip   \n",
       "44          jahreswerte_KL_00044_19720101_20191231_hist.zip   \n",
       "52          jahreswerte_KL_00052_19730101_20011231_hist.zip   \n",
       "61          jahreswerte_KL_00061_19760101_19771231_hist.zip   \n",
       "...                                                     ...   \n",
       "15963       jahreswerte_KL_15963_19530101_20031231_hist.zip   \n",
       "15965       jahreswerte_KL_15965_19700101_19831231_hist.zip   \n",
       "15979       jahreswerte_KL_15979_19480101_19781231_hist.zip   \n",
       "16085       jahreswerte_KL_16085_19610101_19611231_hist.zip   \n",
       "19087       jahreswerte_KL_19087_19580101_19941231_hist.zip   \n",
       "\n",
       "                                                     pname  \n",
       "station_id                                                  \n",
       "1           produkt_klima_jahr_19310101_19851231_00001.txt  \n",
       "3           produkt_klima_jahr_18510101_20101231_00003.txt  \n",
       "44          produkt_klima_jahr_19720101_20191231_00044.txt  \n",
       "52          produkt_klima_jahr_19730101_20011231_00052.txt  \n",
       "61          produkt_klima_jahr_19760101_19771231_00061.txt  \n",
       "...                                                    ...  \n",
       "15963       produkt_klima_jahr_19530101_20031231_15963.txt  \n",
       "15965       produkt_klima_jahr_19700101_19831231_15965.txt  \n",
       "15979       produkt_klima_jahr_19480101_19781231_15979.txt  \n",
       "16085       produkt_klima_jahr_19610101_19611231_16085.txt  \n",
       "19087       produkt_klima_jahr_19580101_19941231_19087.txt  \n",
       "\n",
       "[1076 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>pname</th>\n    </tr>\n    <tr>\n      <th>station_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>jahreswerte_KL_00001_19310101_19851231_hist.zip</td>\n      <td>produkt_klima_jahr_19310101_19851231_00001.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>jahreswerte_KL_00003_18510101_20101231_hist.zip</td>\n      <td>produkt_klima_jahr_18510101_20101231_00003.txt</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>jahreswerte_KL_00044_19720101_20191231_hist.zip</td>\n      <td>produkt_klima_jahr_19720101_20191231_00044.txt</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>jahreswerte_KL_00052_19730101_20011231_hist.zip</td>\n      <td>produkt_klima_jahr_19730101_20011231_00052.txt</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>jahreswerte_KL_00061_19760101_19771231_hist.zip</td>\n      <td>produkt_klima_jahr_19760101_19771231_00061.txt</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15963</th>\n      <td>jahreswerte_KL_15963_19530101_20031231_hist.zip</td>\n      <td>produkt_klima_jahr_19530101_20031231_15963.txt</td>\n    </tr>\n    <tr>\n      <th>15965</th>\n      <td>jahreswerte_KL_15965_19700101_19831231_hist.zip</td>\n      <td>produkt_klima_jahr_19700101_19831231_15965.txt</td>\n    </tr>\n    <tr>\n      <th>15979</th>\n      <td>jahreswerte_KL_15979_19480101_19781231_hist.zip</td>\n      <td>produkt_klima_jahr_19480101_19781231_15979.txt</td>\n    </tr>\n    <tr>\n      <th>16085</th>\n      <td>jahreswerte_KL_16085_19610101_19611231_hist.zip</td>\n      <td>produkt_klima_jahr_19610101_19611231_16085.txt</td>\n    </tr>\n    <tr>\n      <th>19087</th>\n      <td>jahreswerte_KL_19087_19580101_19941231_hist.zip</td>\n      <td>produkt_klima_jahr_19580101_19941231_19087.txt</td>\n    </tr>\n  </tbody>\n</table>\n<p>1076 rows  2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_ftp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            date_from    date_to  altitude  latitude  longitude  \\\n",
       "station_id                                                        \n",
       "73         1953-01-01 2020-12-31       340   48.6159    13.0506   \n",
       "142        1955-01-01 2020-12-31       511   48.4060    11.3117   \n",
       "151        1881-01-01 2020-12-31       382   49.4691    11.8546   \n",
       "154        1994-01-01 2020-12-31       516   48.0197    12.2925   \n",
       "191        1884-01-01 2020-12-31       217   49.9694     9.9114   \n",
       "...               ...        ...       ...       ...        ...   \n",
       "7412       2006-10-01 2020-12-31       340   50.0083     9.4238   \n",
       "7424       2007-01-01 2020-12-31       457   47.7724    12.9073   \n",
       "7431       2008-01-01 2020-12-31       604   48.0130    11.5524   \n",
       "13710      2009-01-01 2020-12-31       490   48.5734    12.2576   \n",
       "15555      2017-01-01 2020-12-31       815   47.8761    10.5849   \n",
       "\n",
       "                               name   state  \n",
       "station_id                                   \n",
       "73             Aldersbach-Kriestorf  Bayern  \n",
       "142           Altomnster-Maisbrunn  Bayern  \n",
       "151         Amberg-Unterammersricht  Bayern  \n",
       "154                Amerang-Pfaffing  Bayern  \n",
       "191              Arnstein-Mdesheim  Bayern  \n",
       "...                             ...     ...  \n",
       "7412             Neuhtten/Spessart  Bayern  \n",
       "7424                         Piding  Bayern  \n",
       "7431           Oberhaching-Laufzorn  Bayern  \n",
       "13710              Landshut-Reithof  Bayern  \n",
       "15555         Kaufbeuren-Oberbeuren  Bayern  \n",
       "\n",
       "[102 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_from</th>\n      <th>date_to</th>\n      <th>altitude</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>name</th>\n      <th>state</th>\n    </tr>\n    <tr>\n      <th>station_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>73</th>\n      <td>1953-01-01</td>\n      <td>2020-12-31</td>\n      <td>340</td>\n      <td>48.6159</td>\n      <td>13.0506</td>\n      <td>Aldersbach-Kriestorf</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>1955-01-01</td>\n      <td>2020-12-31</td>\n      <td>511</td>\n      <td>48.4060</td>\n      <td>11.3117</td>\n      <td>Altomnster-Maisbrunn</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>1881-01-01</td>\n      <td>2020-12-31</td>\n      <td>382</td>\n      <td>49.4691</td>\n      <td>11.8546</td>\n      <td>Amberg-Unterammersricht</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>1994-01-01</td>\n      <td>2020-12-31</td>\n      <td>516</td>\n      <td>48.0197</td>\n      <td>12.2925</td>\n      <td>Amerang-Pfaffing</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>1884-01-01</td>\n      <td>2020-12-31</td>\n      <td>217</td>\n      <td>49.9694</td>\n      <td>9.9114</td>\n      <td>Arnstein-Mdesheim</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7412</th>\n      <td>2006-10-01</td>\n      <td>2020-12-31</td>\n      <td>340</td>\n      <td>50.0083</td>\n      <td>9.4238</td>\n      <td>Neuhtten/Spessart</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>7424</th>\n      <td>2007-01-01</td>\n      <td>2020-12-31</td>\n      <td>457</td>\n      <td>47.7724</td>\n      <td>12.9073</td>\n      <td>Piding</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>7431</th>\n      <td>2008-01-01</td>\n      <td>2020-12-31</td>\n      <td>604</td>\n      <td>48.0130</td>\n      <td>11.5524</td>\n      <td>Oberhaching-Laufzorn</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>13710</th>\n      <td>2009-01-01</td>\n      <td>2020-12-31</td>\n      <td>490</td>\n      <td>48.5734</td>\n      <td>12.2576</td>\n      <td>Landshut-Reithof</td>\n      <td>Bayern</td>\n    </tr>\n    <tr>\n      <th>15555</th>\n      <td>2017-01-01</td>\n      <td>2020-12-31</td>\n      <td>815</td>\n      <td>47.8761</td>\n      <td>10.5849</td>\n      <td>Kaufbeuren-Oberbeuren</td>\n      <td>Bayern</td>\n    </tr>\n  </tbody>\n</table>\n<p>102 rows  7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "station_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}